Sequence to Sequence Model(Encoder-Decoder Model)
===
This is a Video Caption Task solved by a RNN-based sequence-to-sequence model. <br />
Implemented by tensorflow 1.0
<br/>
<br/>
## Requirement
```
python-3.5
tensorflow-1.0
progressbar-3.12.0
numpy-1.12.0
``` 
## tensorflow Implementation of [MIXER](https://github.com/facebookresearch/MIXER)

## Usage

Download dataset from [here](http://speech.ee.ntu.edu.tw/~yangchiyi/MLDS_hw2/MLDS_hw2_data.tar.gz) <br/>
Each features is 80 frames * 4096 feature extracted from CNN model


```
$ python3 video_caption.py
```
For more details, use:

```
$ python3 video_caption.py --help
```

##Performance

Some problems while training

<br/>
<br/>
<br/>

